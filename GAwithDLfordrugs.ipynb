{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.metrics import multilabel_confusion_matrix, matthews_corrcoef\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout, Flatten\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.utils import class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import os\n",
    "%matplotlib inline\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = random.randint(0, 9)\n",
    "print(num)\n",
    "random.seed(num)\n",
    "seed = int(random.SystemRandom().random() * 100)\n",
    "print(seed)\n",
    "random.seed(seed)\n",
    "seed = int(random.SystemRandom().random() * 100)\n",
    "random.seed(seed)\n",
    "print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(name,h,color,modelname):\n",
    "  t = h.history[name]\n",
    "  my_max = max(t)\n",
    "  my_min = min(t)\n",
    "  print(f'Name : {name} max : {my_max} min : {my_min}')\n",
    "  plt.plot(t,color=color,linewidth=3.0)\n",
    "  plt.title(name)\n",
    "  plt.ylabel(name)\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend([name],loc='upper left')\n",
    "  plt.savefig(f'Results/LSTM-{modelname}-{name}.png')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from dataframe\n",
    "df = pd.read_csv('All.csv')\n",
    "df = df.dropna()\n",
    "x = df['review'].values\n",
    "y = df['sentiment-Hand'].values\n",
    "\n",
    "# Tokenize the reviews\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x)\n",
    "x = tokenizer.texts_to_sequences(x)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Pad the reviews\n",
    "max_length = max([len(t) for t in x])\n",
    "\n",
    "my_list = {\n",
    "    \"Anxiety\",\"Post Traumatic Stress Disorde\",\"Bipolar Disorde\",\"Depression\",\"Schizophrenia\",\"Binge Eating Disorde\",\"Anorexia\",\"Bulimia\",\"Aggressive Behavi\",\n",
    "    \"Major Depressive Disorde\",\"Neurosis\",\"Autism\",\"Obsessive Compulsive Disorde\",\"Borderline Personality Disorde\",\"Severe Mood Dysregulation\",\n",
    "    \"Mania\",\"Trichotillomania\",\"Panic Disorde\",\"Psychosis\",\"Dissociative Identity Disorde\",\"ADHD\",\"Agitated State\",\"Agitation\",\"Anxiety and Stress\",\n",
    "    \"Anorexia/Feeding Problems\",\"Neurotic Depression\",\"Persistent Depressive Disorde\",\"Postpartum Depression\",\"Generalized Anxiety Disorde\",\n",
    "    \"Performance Anxiety\",\"mance Anxiety\",\"Social Anxiety Disorde\",\"ICU Agitation\",\"Schizoaffective Disorde\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[(df['condition'].isin(my_list) == False)]\n",
    "x = df['review'].values\n",
    "y = df['sentiment-Hand'].values\n",
    "y_use,y_nuse,x_use, x_nuse  = train_test_split(y,x, test_size=0.95, random_state=seed, shuffle=True)\n",
    "tokenizer.fit_on_texts(x_use)\n",
    "x_seq = tokenizer.texts_to_sequences(x_use)\n",
    "\n",
    "# Pad sequences to a fixed length\n",
    "x_padded = pad_sequences(x_seq, maxlen=1000,)\n",
    "\n",
    "# Compute the class weights\n",
    "class_weights = class_weight.compute_class_weight(                                        \n",
    "                                class_weight = \"balanced\",\n",
    "                                classes = np.unique(y),\n",
    "                                y = y)\n",
    "\n",
    "# Create a dictionary of class weights\n",
    "class_weight_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_use = le.fit_transform(y_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train,y_test,x_train, x_test  = train_test_split(y_use,x_padded, test_size=0.2, random_state=seed, shuffle=True)\n",
    "print(f'Total:{(y.shape[0]/y.shape[0])*100},Train:{(y_train.shape[0]/y.shape[0])*100},Test:{(y_test.shape[0]/y.shape[0])*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Y:Train:{y_train.shape[0]},Test:{y_test.shape[0]}')\n",
    "print(f'X:Train:{x_train.shape[0]},Test:{x_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the fitness function\n",
    "best_fitness = float(\"-inf\")\n",
    "best_model = None\n",
    "best_generation = -1\n",
    "best_fitness_list = []\n",
    "best_model_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "search_space = [(32, 128), # embedding size\n",
    "                (1, 4), # number of neurons in the first hidden layer\n",
    "                (1, 8), # number of neurons in the second hidden layer\n",
    "                (0.0001, 0.1), # learning rate\n",
    "                (32, 256), # batch size\n",
    "                (1, 20)] # number of epochs\n",
    "\n",
    "# Define the population size and number of generations\n",
    "pop_size = 6\n",
    "num_generations = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the fitness function\n",
    "def fitness(params,generation):\n",
    "    global best_fitness, best_model, best_generation\n",
    "\n",
    "    # Define model architecture\n",
    "    inputs = Input(shape=(1000,))\n",
    "    x = Embedding(vocab_size, int(params[0]))(inputs)\n",
    "    x = Bidirectional(LSTM(int(params[1]), return_sequences=True))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Bidirectional(LSTM(int(params[2])))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(3, activation='softmax')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Set early stopping monitor so the model stops training when it won't improve anymore\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=3, \n",
    "                                            verbose=0, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=1e-25)\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', patience=5, verbose=0)\n",
    "    \n",
    "    # Set up model checkpoint to save the best model based on validation accuracy\n",
    "    filepath = f\"Results/acc_model_gen.h5\"\n",
    "    checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                                 monitor='val_accuracy',\n",
    "                                 verbose=0,\n",
    "                                 save_best_only=True,\n",
    "                                 mode='max')\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(x_train, y_train, batch_size=int(params[4]), epochs=int(params[5]), validation_split=0.1,\n",
    "                    callbacks=[learning_rate_reduction, es, checkpoint], class_weight=class_weight_dict, verbose=1)\n",
    "    \n",
    "    # Load best model\n",
    "    model = load_model(filepath)\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
    "    fitness_value = accuracy\n",
    "\n",
    "    # Save the model to a file\n",
    "    model.save('Results/model.h5')\n",
    "\n",
    "    # Update the best model and fitness value\n",
    "    if fitness_value > best_fitness:\n",
    "        best_fitness = fitness_value\n",
    "        best_model = model\n",
    "        best_generation = generation\n",
    "\n",
    "    best_fitness_list.append(best_fitness)\n",
    "    best_model_list.append(best_model)\n",
    "\n",
    "    # Print the fitness value and parameters\n",
    "    print(\"Generation:\", generation, \"Fitness:\", fitness_value, \"Best Fitness:\", best_fitness, \"Params:\", params)\n",
    "\n",
    "    return fitness_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic():\n",
    "\n",
    "    best_fitness = -float('inf')\n",
    "    best_model = None\n",
    "\n",
    "    # Initialize the population\n",
    "    population = []\n",
    "    for i in range(pop_size):\n",
    "        params = []\n",
    "        for space in search_space:\n",
    "            params.append(random.uniform(space[0], space[1]))\n",
    "        population.append(params)\n",
    "\n",
    "    # Initialize lists to store best fitness scores\n",
    "    best_fitness_scores_history = []\n",
    "    times = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Iterate over generations\n",
    "    for gen in range(num_generations):\n",
    "\n",
    "        print(f'Generation {gen + 1}')\n",
    "\n",
    "        # Evaluate fitness of each individual in the population\n",
    "        fitness_scores = []\n",
    "        for individual in population:\n",
    "            fitness_scores.append(fitness(individual,{gen + 1}))\n",
    "\n",
    "        # Normalize fitness scores\n",
    "        sum_fitness = np.sum(fitness_scores)\n",
    "        fitness_probs = [score/sum_fitness for score in fitness_scores]\n",
    "\n",
    "        # Select parents for reproduction\n",
    "        parents = []\n",
    "        for i in range((pop_size // 2)):\n",
    "            idx1 = np.random.choice(range(pop_size), size=1, p=fitness_probs)[0]\n",
    "            idx2 = np.random.choice(range(pop_size), size=1, p=fitness_probs)[0]\n",
    "            parents.append((population[idx1], population[idx2]))\n",
    "\n",
    "        # Reproduce new offspring\n",
    "        offspring = []\n",
    "\n",
    "        for parent1, parent2 in parents:\n",
    "\n",
    "            child1, child2 = [], []\n",
    "\n",
    "            for i in range(len(parent1)):\n",
    "                if random.random() < 0.5:\n",
    "                    child1.append(parent1[i])\n",
    "                    child2.append(parent2[i])\n",
    "                else:\n",
    "                    child1.append(parent2[i])\n",
    "                    child2.append(parent1[i])\n",
    "                \n",
    "            offspring.append(child1)\n",
    "            offspring.append(child2)\n",
    "        \n",
    "        # Mutate some of the offspring\n",
    "        for i in range(len(offspring)):\n",
    "            for j in range(len(offspring[i])):\n",
    "                if random.random() < 0.5:\n",
    "                    space = search_space[j]\n",
    "                    offspring[i][j] = random.uniform(space[0], space[1])\n",
    "\n",
    "        # Replace the old population with the new offspring\n",
    "        population = offspring\n",
    "\n",
    "        # Select the best individual as the result\n",
    "        best_idx = np.argmax(fitness_scores)\n",
    "        best_individual = population[best_idx]\n",
    "        best_fitness_score = fitness_scores[best_idx]\n",
    "        print('Best individual:', best_individual)\n",
    "        print(f'Best fitness score in generation {gen + 1}: {best_fitness_score}')\n",
    "\n",
    "        # Update best model if the current model is better\n",
    "        if best_fitness_score > best_fitness:\n",
    "            best_fitness = best_fitness_score\n",
    "            best_model = load_model('Results/model.h5')\n",
    "            best_model.save('Results/best_model.h5')\n",
    "            print('Best model saved')\n",
    "\n",
    "        # Append best fitness score to history lists\n",
    "        best_fitness_scores_history.append(best_fitness_score)\n",
    "        times.append(time.time() - start_time)\n",
    "\n",
    "        print(f'Time : {time.time() - start_time}')\n",
    "        start_time = time.time()\n",
    "\n",
    "    # Plot best fitness scores over time\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(best_fitness_scores_history, label='Best Fitness Scores')\n",
    "    plt.scatter(np.argmax(best_fitness_scores_history), np.max(best_fitness_scores_history), color='red', label='Max Fitness Score')\n",
    "    plt.scatter(np.argmin(best_fitness_scores_history), np.min(best_fitness_scores_history), color='green', label='Min Fitness Score')\n",
    "    plt.plot(np.ones(num_generations) * np.mean(best_fitness_scores_history), label='Mean Fitness Score')\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Fitness Score')\n",
    "    plt.title('Best Fitness Scores over Generation')\n",
    "    plt.legend()\n",
    "    plt.savefig('Results/Best_Fitness_Scores_over_Generation.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot generations and time\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(times, label='Time (s)')\n",
    "    plt.scatter(np.argmax(times), np.max(times), color='red', label='Max Time')\n",
    "    plt.scatter(np.argmin(times), np.min(times), color='green', label='Min Time')\n",
    "    plt.plot(np.ones(num_generations) * np.mean(times), label='Mean Time')\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Time (s)')\n",
    "    plt.title('Generations and Time')\n",
    "    plt.legend()\n",
    "    plt.savefig('Results/Generations_and_Time.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Save the best model to a file\n",
    "    best_model.save('Results/best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genetic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot best fitness over generations\n",
    "# plt.plot(best_fitness_list)\n",
    "# plt.title('Fitness over Po')\n",
    "# plt.xlabel('Generation')\n",
    "# plt.ylabel('Fitness')\n",
    "\n",
    "# # plot max, min, and mean lines\n",
    "# max_fitness = np.max(best_fitness_list)\n",
    "# min_fitness = np.min(best_fitness_list)\n",
    "# mean_fitness = np.mean(best_fitness_list)\n",
    "\n",
    "# plt.axhline(mean_fitness, color='orange', linestyle='--', label='Mean')\n",
    "# plt.plot(np.argmax(best_fitness_list), max_fitness, 'ro', label='Max')\n",
    "# plt.plot(np.argmin(best_fitness_list), min_fitness, 'go', label='Min')\n",
    "\n",
    "# # add legend\n",
    "# plt.legend()\n",
    "\n",
    "# # save and show plot\n",
    "# plt.savefig('Results/Generations_and_Time.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model('Results/best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization('accuracy',best_model.history,'Blue','Hand')\n",
    "# visualization('loss',best_model.history,'Red','Hand')\n",
    "# visualization('val_accuracy',best_model.history,'Blue','Hand')\n",
    "# visualization('val_loss',best_model.history,'Red','Hand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred = best_model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = le.inverse_transform(y_test)\n",
    "y_true = le.transform(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion matrix:\\n', confusion_matrix(y_true, y_pred))\n",
    "print('Classification report:\\n', classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('None')\n",
    "print('\\n')\n",
    "print('F1 score:', f1_score(y_true, y_pred, average=None))\n",
    "print('Precision score:', precision_score(y_true, y_pred, average=None))\n",
    "print('Recall score:', recall_score(y_true, y_pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Macro')\n",
    "print('\\n')\n",
    "print('F1 score:', f1_score(y_true, y_pred, average='macro'))\n",
    "print('Precision score:', precision_score(y_true, y_pred, average='macro'))\n",
    "print('Recall score:', recall_score(y_true, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Micro')\n",
    "print('\\n')\n",
    "print('F1 score:', f1_score(y_true, y_pred, average='micro'))\n",
    "print('Precision score:', precision_score(y_true, y_pred, average='micro'))\n",
    "print('Recall score:', recall_score(y_true, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Weighted')\n",
    "print('\\n')\n",
    "print('F1 score:', f1_score(y_true, y_pred, average='weighted'))\n",
    "print('Precision score:', precision_score(y_true, y_pred, average='weighted'))\n",
    "print('Recall score:', recall_score(y_true, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(best_model,show_shapes=True,to_file='Results/LSTM-Sentiment-Model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.4)\n",
    "def my_conf_matrix(my_y_test,my_y_pred):\n",
    "  cm = confusion_matrix(my_y_test, my_y_pred)\n",
    "  cm_norm = np.round(cm/np.sum(cm,axis=1).reshape(-1,1),2)\n",
    "  sns.heatmap(cm_norm,cmap='Blues',annot=True,\n",
    "              cbar_kws={'orientation' : 'vertical','label' : 'Color bar'},\n",
    "              fmt='.2f'\n",
    "              )\n",
    "  plt.xlabel('Predicted')\n",
    "  plt.ylabel('Actual')\n",
    "  plt.savefig('Results/LSTM-confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_conf_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save('Results/LSTM-model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcm = multilabel_confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot the confusion matrices\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(12, 4))\n",
    "\n",
    "mcc_sum = 0\n",
    "for i in range(3):\n",
    "    tn, fp, fn, tp = mcm[i].ravel()\n",
    "    mcc = matthews_corrcoef([1 if x == i else 0 for x in y_true], [1 if x == i else 0 for x in y_pred])\n",
    "    print(f\"Class {i}: True Negatives={tn}, False Positives={fp}, False Negatives={fn}, True Positives={tp}, MCC={mcc}\")\n",
    "    mcc_sum += mcc\n",
    "\n",
    "mcc_avg = mcc_sum / 3\n",
    "print(f\"Average MCC: {mcc_avg}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
